{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b60d0de1",
   "metadata": {},
   "source": [
    "# Vector, Time Series and Graph Data Representations of Multivariate Time Series Data for Photospheric Magnetic Field Parameter-based Solar Flare Classification\n",
    "\n",
    "## *by Onur Vural*\n",
    "\n",
    "### This module will allow a step by step guide to run all experiments and document results in a single notebook file\n",
    "--Version h01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d2a285-2053-49b3-9eb6-75fb37f52863",
   "metadata": {},
   "source": [
    "-Prerequisites: To use the partitions, you need to download the SWAN-SF partitions from: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/EBCFKM\n",
    "After downloading, the partitions have to be placed under folder DATA with their original names\n",
    "\n",
    "-As the experiments are being made, the models will be saved under folder MODELS\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8400e24a",
   "metadata": {},
   "source": [
    "# Processing of data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbdad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages required\n",
    "import os\n",
    "import pandas as pd\n",
    "from natsort import natsorted\n",
    "from pathlib import Path\n",
    "\n",
    "# M: Specify the partition to use\n",
    "# Partitions have to be adjacent\n",
    "partitions = ['partition1', 'partition2', 'partition3', 'partition4', 'partition5' ]\n",
    "training_partition = partitions[3]\n",
    "testing_partition = partitions[4]\n",
    "print(\"Training with \", training_partition, \" and testing with \", testing_partition)\n",
    "\n",
    "cur_dir = Path.cwd()\n",
    "parent_folder = cur_dir.parent / 'DATA' \n",
    "\n",
    "# Defining the paths\n",
    "folder_path_flare_train = parent_folder / training_partition / 'FL'\n",
    "folder_path_nonflare_train = parent_folder / training_partition / 'NF'\n",
    "folder_path_flare_test = parent_folder / testing_partition / 'FL'\n",
    "folder_path_nonflare_test = parent_folder / testing_partition / 'NF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeaf79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(folder_path, is_nonflare_train=False):\n",
    "    data_list = []\n",
    "    \n",
    "    if is_nonflare_train:\n",
    "        csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv') and file.startswith('FQ')]\n",
    "    else:\n",
    "        csv_files = natsorted([file for file in os.listdir(folder_path) if file.endswith('.csv')])\n",
    " \n",
    "    # Loop through the sorted CSV files and load them into dataframes\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        # Use the file name (without extension) as the key in the dictionary\n",
    "        df = pd.read_csv(file_path, sep='\\t')\n",
    "        # Extract magnetic field parameter values\n",
    "        first_24_features = df.iloc[:, 1:25]\n",
    "        data_list.append(first_24_features)\n",
    "    \n",
    "    # Detect nan entries\n",
    "    nan_count = 0\n",
    "    indexes_with_nan = []\n",
    "    for index, df in enumerate(data_list):\n",
    "        if df.isna().any().any():\n",
    "            if index not in indexes_with_nan:\n",
    "                nan_count += 1\n",
    "                indexes_with_nan.append(index)\n",
    "    percentageNaN = (nan_count / len(data_list)) * 100\n",
    "    \n",
    "    # Discard nan entries\n",
    "    data_list = [df for index, df in enumerate(data_list) if index not in indexes_with_nan]\n",
    "    \n",
    "    return data_list, percentageNaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a25f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the functions (may take long!)\n",
    "flare_data_list_train, percentageNaN = process_data(folder_path_flare_train)\n",
    "print(\"Number of DataFrames with NaN values among train flare examples: \", percentageNaN)\n",
    "nonflare_data_list_train, percentageNaN  = process_data(folder_path_nonflare_train, True)\n",
    "print(\"Number of DataFrames with NaN values among train nonflare examples: \", percentageNaN)\n",
    "flare_data_list_test, percentageNaN  = process_data(folder_path_flare_test)\n",
    "print(\"Number of DataFrames with NaN values among test flare examples: \", percentageNaN)\n",
    "nonflare_data_list_test, percentageNaN  = process_data(folder_path_nonflare_test)\n",
    "print(\"Number of DataFrames with NaN values among test nonflare examples: \", percentageNaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c44d3d",
   "metadata": {},
   "source": [
    "# Method 2: TS Last Instance - Traditional Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5a02a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def extractLastInstance(flare_data_list, non_flare_data_list):\n",
    "    flare_labels = np.ones(len(flare_data_list))\n",
    "    non_flare_labels = np.zeros(len(non_flare_data_list))\n",
    "    # Combine examples\n",
    "    ts_data_list = flare_data_list + non_flare_data_list\n",
    "    ts_labels = np.concatenate([flare_labels, non_flare_labels])\n",
    "    # shuffle the data\n",
    "    permutation = np.random.permutation(len(ts_data_list))\n",
    "    ts_data_list = [ts_data_list[i] for i in permutation]\n",
    "    ts_labels = ts_labels[permutation]\n",
    "\n",
    "    # Convert df objects to np array format\n",
    "    ts_data_list = np.array([ts.to_numpy() for ts in ts_data_list])\n",
    "    \n",
    "    # Extract the last column for every TS \n",
    "    ts_data_list_LAST = ts_data_list[:, -1, :]   \n",
    "    return ts_data_list, ts_data_list_LAST, ts_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd99a0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data_list_train, ts_data_list_LAST_train, ts_labels_train = extractLastInstance(flare_data_list_train, nonflare_data_list_train)\n",
    "ts_data_list_test, ts_data_list_LAST_test, ts_labels_test = extractLastInstance(flare_data_list_test, nonflare_data_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18450aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classifiers = ['SVC', 'KNC', 'DT', 'LR', 'MLP']\n",
    "def train_test_classifier_method2(ts_data_list_train_LAST, ts_labels_train, ts_data_list_test_LAST, ts_labels_test, classifier_name):\n",
    "    # Create and train the classifier\n",
    "    if classifier_name == 'SVC':\n",
    "        classifier = SVC(class_weight='balanced')\n",
    "    elif classifier_name == 'KNC':\n",
    "        classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "    elif classifier_name == 'DT':\n",
    "        classifier = DecisionTreeClassifier(random_state=42)\n",
    "    elif classifier_name == 'LR':\n",
    "        classifier = LogisticRegression(max_iter=100000)\n",
    "    elif classifier_name == 'MLP':\n",
    "        classifier = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000) \n",
    "    else :\n",
    "        classifier = SVC(class_weight='balanced')\n",
    "    # train selected classifier        \n",
    "    classifier.fit(ts_data_list_train_LAST, ts_labels_train)\n",
    "    # test selected classifier on unseen data\n",
    "    predictions = classifier.predict(ts_data_list_test_LAST)\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    conf_matrix = confusion_matrix(ts_labels_test, predictions)\n",
    "\n",
    "    # Calculate True Positives, True Negatives, False Positives, and False Negatives\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "    # Calculate True Skill Statistics (TSS)\n",
    "    tss = (tp / (tp + fn)) - (fp / (fp + tn))\n",
    "\n",
    "    # Calculate Heidke Skill Score 1 (HSS1)\n",
    "    hss1 = (tp / (tp + fn) )*(2 - (tp + fp)/tp )\n",
    "\n",
    "    # Calculate Heidke Skill Score 2 (HSS2)\n",
    "    hss2 = (2 * (tp * tn - fp * fn)) / ((tp + fn) * (tn + fn) + (tp + fp) * (tn + fp))\n",
    "\n",
    "    # Calculate F1 Score\n",
    "    f1 = f1_score(ts_labels_test, predictions)\n",
    "\n",
    "    # Calculate Gilbert Skill Score\n",
    "    gilbert = (tp - (tp + fn) * (tp + fp) / (tp + tn + fp + fn)) / (tp + tn - (tp + fn) * (tp + fp) / (tp + tn + fp + fn))\n",
    "\n",
    "    # Calculate ROC AUC score\n",
    "    roc_auc = roc_auc_score(ts_labels_test, predictions)\n",
    "    \n",
    "    # save the model\n",
    "    cur_dir = Path.cwd()\n",
    "    model_name = training_partition + '_' + testing_partition + '_' + classifier_name + '_model_tsLAST.pkl'\n",
    "    model_path = cur_dir.parent / 'MODELS' / model_name\n",
    "    \n",
    "    with open(model_path, 'wb') as model_file:\n",
    "        pickle.dump(classifier, model_file)\n",
    "\n",
    "    print(\"Saved \", classifier_name,\" to\", model_path)\n",
    "    # Print the results\n",
    "    print(classifier_name, \" Model Evaluation Metrics:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"True Skill Statistics (TSS):\", tss)\n",
    "    print(\"Heidke Skill Score 1 (HSS1):\", hss1)\n",
    "    print(\"Heidke Skill Score 2 (HSS2):\", hss2)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Gilbert Skill Score:\", gilbert)\n",
    "    print(\"ROC AUC Score:\", roc_auc)\n",
    "    print(\"********************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab1dc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all classifiers\n",
    "for classifier_name in classifiers:\n",
    "    train_test_classifier_method2(ts_data_list_LAST_train, ts_labels_train, ts_data_list_LAST_test, ts_labels_test, classifier_name)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fe0df1",
   "metadata": {},
   "source": [
    "# Method 3: TS Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407f5ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score\n",
    "from sktime.classification.shapelet_based import ShapeletTransformClassifier\n",
    "from sktime.classification.sklearn import RotationForest\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "\n",
    "classifiers_ts = ['ST','TSFC','ROCKET']\n",
    "def train_test_classifier_method3(ts_data_list_train, ts_labels_train, ts_data_list_test, ts_labels_test, classifier_name):\n",
    "    \n",
    "    # Create and train the classifier\n",
    "    if classifier_name == 'ST':\n",
    "        classifier = ShapeletTransformClassifier(\n",
    "                        estimator=RotationForest(n_estimators=3),\n",
    "                        n_shapelet_samples=100,\n",
    "                        max_shapelets=10,\n",
    "                        batch_size=20)\n",
    "        classifier.fit(ts_data_list_train, ts_labels_train)\n",
    "        predictions = classifier.predict(ts_data_list_test)\n",
    "    elif classifier_name == 'TSFC':\n",
    "        ts_data_list_train_concatenated = ts_data_list_train.reshape((len(ts_data_list_train), -1))\n",
    "        classifier = TimeSeriesForestClassifier(n_estimators=100, random_state=42)\n",
    "        classifier.fit(ts_data_list_train_concatenated, ts_labels_train)\n",
    "        ts_data_list_test_concatenated = ts_data_list_test.reshape((len(ts_data_list_test), -1))    \n",
    "        predictions = classifier.predict(ts_data_list_test_concatenated)\n",
    "    elif classifier_name == 'ROCKET':\n",
    "        classifier = RocketClassifier(num_kernels=500)\n",
    "        classifier.fit(ts_data_list_train, ts_labels_train)\n",
    "        predictions = classifier.predict(ts_data_list_test)\n",
    "    else:\n",
    "        classifier = RocketClassifier(num_kernels=500)\n",
    "        classifier.fit(ts_data_list_train, ts_labels_train)\n",
    "        predictions = classifier.predict(ts_data_list_test)\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    conf_matrix = confusion_matrix(ts_labels_test, predictions)\n",
    "\n",
    "    # Calculate True Positives, True Negatives, False Positives, and False Negatives\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "    # Calculate True Skill Statistics (TSS)\n",
    "    tss = (tp / (tp + fn)) - (fp / (fp + tn))\n",
    "\n",
    "    # Calculate Heidke Skill Score 1 (HSS1)\n",
    "    hss1 = (tp / (tp + fn) )*(2 - (tp + fp)/tp )\n",
    "\n",
    "    # Calculate Heidke Skill Score 2 (HSS2)\n",
    "    hss2 = (2 * (tp * tn - fp * fn)) / ((tp + fn) * (tn + fn) + (tp + fp) * (tn + fp))\n",
    "\n",
    "    # Calculate F1 Score\n",
    "    f1 = f1_score(ts_labels_test, predictions)\n",
    "\n",
    "    # Calculate Gilbert Skill Score\n",
    "    gilbert = (tp - (tp + fn) * (tp + fp) / (tp + tn + fp + fn)) / (tp + tn - (tp + fn) * (tp + fp) / (tp + tn + fp + fn))\n",
    "\n",
    "    # Calculate ROC AUC score\n",
    "    roc_auc = roc_auc_score(ts_labels_test, predictions)\n",
    "    \n",
    "    # save the model\n",
    "    cur_dir = Path.cwd()\n",
    "    model_name = training_partition + '_' + testing_partition + '_' + classifier_name + '_model_ts.pkl'\n",
    "    model_path = cur_dir.parent / 'MODELS' / model_name\n",
    "    \n",
    "    with open(model_path, 'wb') as model_file:\n",
    "        pickle.dump(classifier, model_file)\n",
    "\n",
    "    print(\"Saved \", classifier_name,\" to\", model_path)\n",
    "    # Print the results\n",
    "    print(classifier_name, \" Model Evaluation Metrics:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"True Skill Statistics (TSS):\", tss)\n",
    "    print(\"Heidke Skill Score 1 (HSS1):\", hss1)\n",
    "    print(\"Heidke Skill Score 2 (HSS2):\", hss2)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Gilbert Skill Score:\", gilbert)\n",
    "    print(\"ROC AUC Score:\", roc_auc)\n",
    "    print(\"********************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a44a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and save all classifiers\n",
    "for classifier_name in classifiers_ts:\n",
    "    train_test_classifier_method3(ts_data_list_train, ts_labels_train, ts_data_list_test, ts_labels_test, classifier_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc0861f",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c49c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Assuming you have ts_data_list_train, ts_labels_train, ts_data_list_test, ts_labels_test\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data_list, labels):\n",
    "        self.data_list = data_list\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = torch.Tensor(self.data_list[index])  # Assuming your data is already in tensor format\n",
    "        label = torch.Tensor([self.labels[index]])\n",
    "        return {'x': data, 'y': label}\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = TimeSeriesDataset(ts_data_list_train, ts_labels_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_dataset = TimeSeriesDataset(ts_data_list_test, ts_labels_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98ffae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming you have train_loader and test_loader already defined\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        out = self.fc(h_n[-1, :, :])\n",
    "        return torch.sigmoid(out)\n",
    "\n",
    "# Initialize LSTM model\n",
    "input_size = 24  # Assuming each time step has 24 features\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "output_size = 1  # Binary classification\n",
    "\n",
    "lstm_model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "# Initialize LSTM model, loss function, and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    lstm_model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
    "        data, labels = batch['x'], batch['y']\n",
    "        optimizer.zero_grad()\n",
    "        output = lstm_model(data)\n",
    "        loss = criterion(output, labels.view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update metrics\n",
    "        total_loss += loss.item()\n",
    "        total_samples += len(labels) \n",
    "        predicted_labels = (output >= 0.5).float()\n",
    "        correct_predictions += (predicted_labels == labels.view(-1, 1)).sum().item()\n",
    "\n",
    "    average_loss = total_loss / total_samples\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    train_losses.append(average_loss)\n",
    "    train_accuracies.append(accuracy)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c038a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dir = Path.cwd()\n",
    "model_name = training_partition + '_' + testing_partition + '_LSTM_model_ts.pkl'\n",
    "model_path = cur_dir.parent / 'MODELS' / model_name\n",
    "torch.save(lstm_model.state_dict(), model_path)\n",
    "print(f\"Saved LSTM model to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250b94c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Epoch vs Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Epoch vs Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108bcb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "lstm_model.eval()\n",
    "true_labels, predicted_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc='Testing'):\n",
    "        data, labels = batch['x'], batch['y']\n",
    "        output = (lstm_model(data) >= 0.5).float()\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(output.cpu().numpy())\n",
    "\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Extract values from confusion matrix\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate True Skill Statistics (TSS)\n",
    "tss = (tp / (tp + fn)) - (fp / (fp + tn))\n",
    "\n",
    "# Calculate Heidke Skill Score 1 (HSS1)\n",
    "hss1 = (tp / (tp + fn)) * (2 - (tp + fp) / tp)\n",
    "\n",
    "# Calculate Heidke Skill Score 2 (HSS2)\n",
    "hss2 = (2 * (tp * tn - fp * fn)) / ((tp + fn) * (tn + fn) + (tp + fp) * (tn + fp))\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate Gilbert Skill Score\n",
    "gilbert = (tp - (tp + fn) * (tp + fp) / (tp + tn + fp + fn)) / (\n",
    "        tp + tn - (tp + fn) * (tp + fp) / (tp + tn + fp + fn)\n",
    ")\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "roc_auc = roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "# Print the results\n",
    "print(\"LSTM Model Evaluation Metrics:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"True Skill Statistics (TSS):\", tss)\n",
    "print(\"Heidke Skill Score 1 (HSS1):\", hss1)\n",
    "print(\"Heidke Skill Score 2 (HSS2):\", hss2)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Gilbert Skill Score:\", gilbert)\n",
    "print(\"ROC AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3658fd90",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6053c108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "  \n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, hidden = self.rnn(x)\n",
    "        out = self.fc(hidden[-1, :, :])  # Take the hidden state of the last time step\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 24  # Number of features\n",
    "hidden_size = 64  # Number of hidden units\n",
    "output_size = 1  # Output size (1 for binary classification)\n",
    "\n",
    "# Create an instance of the RNN model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "rnn_model = RNN(input_size=input_size, hidden_size=hidden_size, output_size=output_size).to(device)   \n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(rnn_model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    rnn_model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
    "        data, labels = batch['x'], batch['y']\n",
    "        optimizer.zero_grad()\n",
    "        output = rnn_model(data)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update metrics\n",
    "        total_loss += loss.item()\n",
    "        total_samples += labels.size(0)\n",
    "        predicted_labels = (output >= 0.5).float()\n",
    "        correct_predictions += (predicted_labels == labels).sum().item()\n",
    "\n",
    "    average_loss = total_loss / total_samples\n",
    "    accuracy = correct_predictions / total_samples\n",
    "\n",
    "    train_losses.append(average_loss)\n",
    "    train_accuracies.append(accuracy)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0734a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dir = Path.cwd()\n",
    "model_name = training_partition + '_' + testing_partition + '_RNN_model_ts.pkl'\n",
    "model_path = cur_dir.parent / 'MODELS' / model_name\n",
    "torch.save(rnn_model.state_dict(), model_path)\n",
    "print(f\"Saved RNN model to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8af5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Epoch vs Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Epoch vs Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e38aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "rnn_model.eval()\n",
    "true_labels, predicted_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc='Testing'):\n",
    "        data, labels = batch['x'], batch['y']\n",
    "        output = (rnn_model(data) >= 0.5).float()\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(output.cpu().numpy())\n",
    "\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Extract values from confusion matrix\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate True Skill Statistics (TSS)\n",
    "tss = (tp / (tp + fn)) - (fp / (fp + tn))\n",
    "\n",
    "# Calculate Heidke Skill Score 1 (HSS1)\n",
    "hss1 = (tp / (tp + fn)) * (2 - (tp + fp) / tp)\n",
    "\n",
    "# Calculate Heidke Skill Score 2 (HSS2)\n",
    "hss2 = (2 * (tp * tn - fp * fn)) / ((tp + fn) * (tn + fn) + (tp + fp) * (tn + fp))\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate Gilbert Skill Score\n",
    "gilbert = (tp - (tp + fn) * (tp + fp) / (tp + tn + fp + fn)) / (\n",
    "        tp + tn - (tp + fn) * (tp + fp) / (tp + tn + fp + fn)\n",
    ")\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "roc_auc = roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "# Print the results\n",
    "print(\"RNN Model Evaluation Metrics:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"True Skill Statistics (TSS):\", tss)\n",
    "print(\"Heidke Skill Score 1 (HSS1):\", hss1)\n",
    "print(\"Heidke Skill Score 2 (HSS2):\", hss2)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Gilbert Skill Score:\", gilbert)\n",
    "print(\"ROC AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22987fac",
   "metadata": {},
   "source": [
    "# METHOD 1: Graph-based Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc71b75",
   "metadata": {},
   "source": [
    "Creation of Pearson correlation matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d38798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "cur_dir = Path.cwd()\n",
    "correlation_folder = cur_dir.parent / 'DATA' / 'pearson_correlation'\n",
    "\n",
    "def calculate_correlation_matrix(data_list, is_flare, partition_name, train_or_test):\n",
    "    if is_flare:\n",
    "        name = 'flare'\n",
    "    else:\n",
    "        name = 'nonflare'\n",
    "        \n",
    "    f_name = partition_name + '_' + train_or_test\n",
    "    new_folder_path = os.path.join(correlation_folder, f_name)\n",
    "    # Check whether the folder exists first, if not, create it\n",
    "    if not os.path.exists(new_folder_path):\n",
    "        os.makedirs(new_folder_path)\n",
    "        \n",
    "    # Iterate through the list of DataFrames in data_list\n",
    "    for index, df in enumerate(data_list):\n",
    "        # Compute the correlation matrix for the DataFrame object\n",
    "        correlation_matrix = df.corr()\n",
    "        \n",
    "        # Remove self-loops\n",
    "        np.fill_diagonal(correlation_matrix.values, 0)\n",
    "        \n",
    "        # Threshold by zero\n",
    "        correlation_matrix[correlation_matrix < 0] = 0\n",
    "    \n",
    "        # Define the file path for saving the correlation matrix\n",
    "        file_path = os.path.join(new_folder_path, f\"{name}_correlation_matrix_{index}.csv\")\n",
    "        \n",
    "        # Save the correlation matrix to the specified file path\n",
    "        correlation_matrix.to_csv(file_path, index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196b6722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrices for train and test partitions and save them into their respective folders\n",
    "# train\n",
    "calculate_correlation_matrix(flare_data_list_train, is_flare=True, \n",
    "                             partition_name=training_partition, train_or_test='train')\n",
    "calculate_correlation_matrix(nonflare_data_list_train, is_flare=False, \n",
    "                             partition_name=training_partition, train_or_test='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60db8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "calculate_correlation_matrix(flare_data_list_test, is_flare=True, \n",
    "                             partition_name=testing_partition, train_or_test='test')\n",
    "calculate_correlation_matrix(nonflare_data_list_test, is_flare=False, \n",
    "                             partition_name=testing_partition, train_or_test='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6735e529",
   "metadata": {},
   "source": [
    "Creation of Euclidian distance matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e44f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cur_dir = Path.cwd()\n",
    "euclidian_folder = cur_dir.parent / 'DATA' / 'euclidian_distance'\n",
    "# For z-Normalization\n",
    "scaler = StandardScaler() \n",
    "\n",
    "def calculate_euclidian_matrix(data_list, is_flare, partition_name, train_or_test):\n",
    "    if is_flare:\n",
    "        name = 'flare'\n",
    "    else:\n",
    "        name = 'nonflare'\n",
    "    \n",
    "    f_name = partition_name + '_' + train_or_test\n",
    "    new_folder_path = os.path.join(euclidian_folder, f_name)\n",
    "    # Check whether the folder exists first, if not, create it\n",
    "    if not os.path.exists(new_folder_path):\n",
    "        os.makedirs(new_folder_path)\n",
    "        \n",
    "    # Iterate through the list of DataFrames in data_list\n",
    "    for index, df in enumerate(data_list):\n",
    "        row_names = df.columns\n",
    "        col_names = df.columns\n",
    "        ft_num = df.shape[1]\n",
    "        euclidian_distances = np.zeros((ft_num, ft_num))\n",
    "    \n",
    "        # NORMALIZE THE DATA COLUMNWISE BEFORE DISTANCE CALCULATION\n",
    "        normalized_df = scaler.fit_transform(df)\n",
    "        # Create a new DataFrame with the normalized values\n",
    "        normalized_df = pd.DataFrame(normalized_df, columns=df.columns, index=df.index)\n",
    "\n",
    "        for i in range(ft_num):\n",
    "            for j in range(i, ft_num):\n",
    "                # Feature i and j and j: euclidean distance between i and j\n",
    "                euclidian_distance = np.linalg.norm(normalized_df.iloc[:, i] - normalized_df.iloc[:, j])\n",
    "                euclidian_distances[i, j] = euclidian_distance\n",
    "                euclidian_distances[j, i] = euclidian_distance\n",
    "\n",
    "        # Save the Euclidean distances as a CSV file\n",
    "        euclidian_distances_df = pd.DataFrame(euclidian_distances, index=row_names, columns=col_names)\n",
    "        dist_file_path = os.path.join(new_folder_path, f\"{name}_euclidian_matrix_{index}.csv\")\n",
    "        euclidian_distances_df.to_csv(dist_file_path)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cb6c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create euclidian matrices for train and test partitions and save them into their respective folders\n",
    "# train\n",
    "calculate_euclidian_matrix(flare_data_list_train, is_flare=True, \n",
    "                           partition_name=training_partition, train_or_test='train')\n",
    "calculate_euclidian_matrix(nonflare_data_list_train, is_flare=False, \n",
    "                           partition_name=training_partition, train_or_test='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa0cf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "calculate_euclidian_matrix(flare_data_list_test, is_flare=True, \n",
    "                           partition_name=testing_partition, train_or_test='test')\n",
    "calculate_euclidian_matrix(nonflare_data_list_test, is_flare=False, \n",
    "                           partition_name=testing_partition, train_or_test='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22c5aeb",
   "metadata": {},
   "source": [
    "Creation of graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d896f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "cur_dir = Path.cwd()\n",
    "matrix_folder = cur_dir.parent / 'DATA' # For input matrix, the type will be specified\n",
    "graph_folder = cur_dir.parent / 'DATA' / 'graphs' # For output graphs\n",
    "graph_categories = ['pearson_correlation','euclidian_distance']\n",
    "\n",
    "def create_graphs(is_flare, partition_name, graph_category, train_or_test):\n",
    "    if is_flare:\n",
    "        name = 'flare'\n",
    "    else:\n",
    "        name = 'nonflare'    \n",
    "        \n",
    "    f_name = partition_name + '_' + train_or_test\n",
    "    input_folder_path = matrix_folder / graph_category / f_name\n",
    "    new_folder_path = graph_folder / graph_category / f_name \n",
    "    # Check whether the folder exists first, if not, create it\n",
    "    if not os.path.exists(new_folder_path):\n",
    "        os.makedirs(new_folder_path)\n",
    "    \n",
    "    # Iterate through the matrices, convert them into graph objects\n",
    "    for file in os.listdir(input_folder_path):\n",
    "        if file.endswith('.csv'):\n",
    "            # Read the coMatrix\n",
    "            file_path = os.path.join(input_folder_path, file)\n",
    "            instance = pd.read_csv(file_path, index_col=0)\n",
    "        \n",
    "            if graph_category == 'pearson_correlation':\n",
    "                # Create graph\n",
    "                myG = nx.Graph(instance.values)\n",
    "            elif graph_category == 'euclidian_distance':\n",
    "                THRESHOLD_VALUE = 10\n",
    "                myG = nx.Graph()\n",
    "                # Add nodes for each feature in the DataFrame with their names\n",
    "                for feature in instance.columns:\n",
    "                    myG.add_node(feature)\n",
    "                # Apply threshold principle when creating the edges\n",
    "                n = len(instance.columns)\n",
    "                for i in range(n):\n",
    "                    for j in range(i + 1, n):\n",
    "                        if np.abs(instance.iat[i, j]) < THRESHOLD_VALUE:\n",
    "                            # Add an edge between the corresponding nodes and assign their names as attributes\n",
    "                            node1 = instance.columns[i]\n",
    "                            node2 = instance.columns[j]\n",
    "                            myG.add_edge(node1, node2)\n",
    "            # Save graph\n",
    "            outputG_path = os.path.join(new_folder_path, f\"{file}.graph\")\n",
    "            with open(outputG_path, 'wb') as f:\n",
    "                pickle.dump(myG, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d72a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call def to create desired graphs and save them\n",
    "create_graphs(is_flare=True, partition_name=training_partition, \n",
    "              graph_category='pearson_correlation', train_or_test='train')\n",
    "create_graphs(is_flare=False, partition_name=training_partition, \n",
    "              graph_category='pearson_correlation', train_or_test='train')\n",
    "\n",
    "create_graphs(is_flare=True, partition_name=testing_partition, \n",
    "              graph_category='pearson_correlation', train_or_test='test')\n",
    "create_graphs(is_flare=False, partition_name=testing_partition, \n",
    "              graph_category='pearson_correlation', train_or_test='test')\n",
    "\n",
    "create_graphs(is_flare=True, partition_name=training_partition, \n",
    "              graph_category='euclidian_distance', train_or_test='train')\n",
    "create_graphs(is_flare=False, partition_name=training_partition, \n",
    "              graph_category='euclidian_distance', train_or_test='train')\n",
    "\n",
    "create_graphs(is_flare=True, partition_name=testing_partition, \n",
    "              graph_category='euclidian_distance', train_or_test='test')\n",
    "create_graphs(is_flare=False, partition_name=testing_partition, \n",
    "              graph_category='euclidian_distance', train_or_test='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740b86df",
   "metadata": {},
   "source": [
    "Processing of the graphs by extracting the degree information as a vector along with label information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c56054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "def process_graphs_m11(partition_name, graph_category, train_or_test):\n",
    "    f_name = partition_name + '_' + train_or_test\n",
    "    cur_dir = Path.cwd()\n",
    "    graph_folder_input = cur_dir.parent / 'DATA' / 'graphs' # For specified graph path\n",
    "    graph_folder_input = graph_folder_input / graph_category / f_name\n",
    "    graph_vectors = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate through all files in the folder\n",
    "    for filename in os.listdir(graph_folder_input):\n",
    "        graph_path = os.path.join(graph_folder_input, filename)\n",
    "        try:\n",
    "            with open(graph_path, 'rb') as f:\n",
    "                G = pickle.load(f)\n",
    "            \n",
    "            if graph_category == 'pearson_correlation': \n",
    "                # Compute node degrees\n",
    "                degrees = [deg for node, deg in G.degree() if node != len(G.nodes) - 1]\n",
    "            elif graph_category == 'euclidian_distance':\n",
    "                # Compute node degrees\n",
    "                degrees = [deg for node, deg in G.degree()]\n",
    "           \n",
    "            # Determine label based on filename\n",
    "            if filename.startswith('flare'):\n",
    "                label = 1\n",
    "            elif filename.startswith('nonflare'):\n",
    "                label = 0\n",
    "        \n",
    "            # Append degrees and label to lists\n",
    "            graph_vectors.append(degrees)\n",
    "            labels.append(label)\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filename}: {str(e)}\")\n",
    "\n",
    "    # Convert lists to NumPy arrays\n",
    "    graph_matrix = np.array(graph_vectors)\n",
    "    label_vector = np.array(labels)\n",
    "    print(\"Graph Matrix Shape:\", graph_matrix.shape)\n",
    "    print(\"Label Vector Shape:\", label_vector.shape)\n",
    "    return graph_matrix, label_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bced3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_matrix_cor_train, label_vector_cor_train=process_graphs_m11(partition_name=training_partition, \n",
    "                                                                  graph_category='pearson_correlation', train_or_test='train')\n",
    "graph_matrix_cor_test, label_vector_cor_test=process_graphs_m11(partition_name=testing_partition, \n",
    "                                                                graph_category='pearson_correlation', train_or_test='test')\n",
    "\n",
    "graph_matrix_euc_train, label_vector_euc_train = process_graphs_m11(partition_name=training_partition, \n",
    "                                                                    graph_category='euclidian_distance', train_or_test='train')\n",
    "graph_matrix_euc_test, label_vector_euc_test = process_graphs_m11(partition_name=testing_partition, \n",
    "                                                                  graph_category='euclidian_distance', train_or_test='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d0082a",
   "metadata": {},
   "source": [
    "# Method 1.1: Degree Vector as it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f4725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classifiers = ['SVC', 'KNC', 'DT', 'LR', 'MLP']\n",
    "def train_test_classifier_method11(graph_category, graph_matrix_train, label_vector_train, graph_matrix_test, label_vector_test, classifier_name):\n",
    "    # Create and train the classifier\n",
    "    if classifier_name == 'SVC':\n",
    "        classifier = SVC(class_weight='balanced')\n",
    "    elif classifier_name == 'KNC':\n",
    "        classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "    elif classifier_name == 'DT':\n",
    "        classifier = DecisionTreeClassifier(random_state=42)\n",
    "    elif classifier_name == 'LR':\n",
    "        classifier = LogisticRegression(max_iter=10000)\n",
    "    elif classifier_name == 'MLP':\n",
    "        classifier = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000) \n",
    "    else :\n",
    "        classifier = SVC(class_weight='balanced')\n",
    "    # train selected classifier        \n",
    "    classifier.fit(graph_matrix_train, label_vector_train)\n",
    "    # test selected classifier on unseen data\n",
    "    predictions = classifier.predict(graph_matrix_test)\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    conf_matrix = confusion_matrix(label_vector_test, predictions)\n",
    "\n",
    "    # Calculate True Positives, True Negatives, False Positives, and False Negatives\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "    # Calculate True Skill Statistics (TSS)\n",
    "    tss = (tp / (tp + fn)) - (fp / (fp + tn))\n",
    "\n",
    "    # Calculate Heidke Skill Score 1 (HSS1)\n",
    "    hss1 = (tp / (tp + fn) )*(2 - (tp + fp)/tp )\n",
    "\n",
    "    # Calculate Heidke Skill Score 2 (HSS2)\n",
    "    hss2 = (2 * (tp * tn - fp * fn)) / ((tp + fn) * (tn + fn) + (tp + fp) * (tn + fp))\n",
    "\n",
    "    # Calculate F1 Score\n",
    "    f1 = f1_score(label_vector_test, predictions)\n",
    "\n",
    "    # Calculate Gilbert Skill Score\n",
    "    gilbert = (tp - (tp + fn) * (tp + fp) / (tp + tn + fp + fn)) / (tp + tn - (tp + fn) * (tp + fp) / (tp + tn + fp + fn))\n",
    "\n",
    "    # Calculate ROC AUC score\n",
    "    roc_auc = roc_auc_score(label_vector_test, predictions)\n",
    "    \n",
    "    # save the model\n",
    "    if graph_category == 'pearson_correlation':\n",
    "        codeName = 'cor'\n",
    "    elif graph_category == 'euclidian_distance':\n",
    "        codeName = 'euc'\n",
    "        \n",
    "    cur_dir = Path.cwd()\n",
    "    model_name = training_partition + '_' + testing_partition + '_' + classifier_name + '_model_' + codeName + '.pkl'\n",
    "    model_path = cur_dir.parent / 'MODELS' / model_name\n",
    "    \n",
    "    with open(model_path, 'wb') as model_file:\n",
    "        pickle.dump(classifier, model_file)\n",
    "\n",
    "    print(\"Saved \", classifier_name,\" to\", )\n",
    "    # Print the results\n",
    "    print(classifier_name, \" Model Evaluation Metrics:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"True Skill Statistics (TSS):\", tss)\n",
    "    print(\"Heidke Skill Score 1 (HSS1):\", hss1)\n",
    "    print(\"Heidke Skill Score 2 (HSS2):\", hss2)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Gilbert Skill Score:\", gilbert)\n",
    "    print(\"ROC AUC Score:\", roc_auc)\n",
    "    print(\"********************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce70f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all classifiers (COR)\n",
    "for classifier_name in classifiers:\n",
    "    train_test_classifier_method11('pearson_correlation', graph_matrix_cor_train, label_vector_cor_train, \n",
    "                                   graph_matrix_cor_test, label_vector_cor_test, classifier_name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44bf743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all classifiers (EUC)\n",
    "for classifier_name in classifiers:\n",
    "    train_test_classifier_method11('euclidian_distance', graph_matrix_euc_train, label_vector_euc_train, \n",
    "                                   graph_matrix_euc_test, label_vector_euc_test, classifier_name)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620770b3",
   "metadata": {},
   "source": [
    "# Method 1.2: Degree Vector with Node Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3bd0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "def process_graphs_m12(partition_name, graph_category, train_or_test):\n",
    "    f_name = partition_name + '_' + train_or_test\n",
    "    cur_dir = Path.cwd()\n",
    "    graph_folder_input = cur_dir.parent / 'DATA' / 'graphs' # For specified graph path\n",
    "    graph_folder_input = graph_folder_input / graph_category / f_name\n",
    "    flare_graphs = []\n",
    "    flare_labels = []\n",
    "    nonflare_graphs = []\n",
    "    nonflare_labels = []\n",
    "\n",
    "    # Iterate through all files in the folder\n",
    "    for filename in os.listdir(graph_folder_input):\n",
    "        graph_path = os.path.join(graph_folder_input, filename)\n",
    "        try:\n",
    "            with open(graph_path, 'rb') as f:\n",
    "                myG = pickle.load(f)\n",
    "           \n",
    "            # Determine label based on filename\n",
    "            if filename.startswith('flare'):\n",
    "                label = 1\n",
    "                # only add to list if it is connected graph\n",
    "                if nx.is_connected(myG): \n",
    "                    flare_graphs.append((myG, label))\n",
    "                else:\n",
    "                    continue\n",
    "            elif filename.startswith('nonflare'):\n",
    "                label = 0\n",
    "                # only add to list if it is connected graph\n",
    "                if nx.is_connected(myG): \n",
    "                    nonflare_graphs.append((myG, label))\n",
    "                else:\n",
    "                    continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filename}: {str(e)}\")\n",
    "\n",
    "    graphs = flare_graphs + nonflare_graphs\n",
    "    # Shuffle the balanced dataset\n",
    "    random.shuffle(graphs)\n",
    "    graph_list = [graph for graph, label in graphs]\n",
    "    label_vector = [label for graph, label in graphs]\n",
    "    label_vector = np.array(label_vector)    \n",
    "    return graph_list, label_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9d2da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_list_cor_train, label_vector_cor_train = process_graphs_m12(partition_name=training_partition, \n",
    "                                                                  graph_category='pearson_correlation', train_or_test='train')\n",
    "graph_list_cor_test, label_vector_cor_test = process_graphs_m12(partition_name=testing_partition, \n",
    "                                                                  graph_category='pearson_correlation', train_or_test='test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3256c1d-5244-4867-8a41-eb608b0e5643",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_list_euc_train, label_vector_euc_train = process_graphs_m12(partition_name=training_partition, \n",
    "                                                                  graph_category='euclidian_distance', train_or_test='train')\n",
    "graph_list_euc_test, label_vector_euc_test = process_graphs_m12(partition_name=testing_partition, \n",
    "                                                                graph_category='euclidian_distance', train_or_test='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5738af37",
   "metadata": {},
   "source": [
    "# Laplacian Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f5ea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "# Set dimension as 14 (75% representation power)\n",
    "def laplacian_embedding(d, graph_list, graph_category):\n",
    "    # For Z-normalization\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    graph_laplacian_node_embeddings_list = []\n",
    "    \n",
    "    # Iterate through each graph in graph_list\n",
    "    for graph in graph_list:\n",
    "\n",
    "        # Calculate the Laplacian\n",
    "        L = nx.laplacian_matrix(graph).toarray()\n",
    "        L = L.astype('float64')\n",
    "        # Perform eigendecomposition of L\n",
    "        eigenvalues, eigenvectors = eigsh(L, k=d, which='LM')\n",
    "    \n",
    "\n",
    "        # Sort eigenvalues and select the top d eigenvectors\n",
    "        sorted_indices = np.argsort(eigenvalues)\n",
    "        top_indices = sorted_indices[:d]\n",
    "        embedding_matrix = eigenvectors[:, top_indices]\n",
    "    \n",
    "        normalized_embedding_matrix = scaler.fit_transform(embedding_matrix)\n",
    "        graph_laplacian_node_embeddings_list.append(normalized_embedding_matrix)\n",
    "        \n",
    "    # flatten as 1-D feature respresentation\n",
    "    flat_embeddings = [emb.flatten() for emb in graph_laplacian_node_embeddings_list]\n",
    "    X_train = np.array(flat_embeddings)\n",
    "    return X_train   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c55a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    # Warning-causing lines of code here\n",
    "    X_train_cor_lap = laplacian_embedding(14, graph_list_cor_train, graph_category='pearson_correlation')\n",
    "    X_test_cor_lap = laplacian_embedding(14, graph_list_cor_test, graph_category='pearson_correlation')\n",
    "\n",
    "    X_train_euc_lap = laplacian_embedding(14, graph_list_euc_train, graph_category='euclidian_distance')\n",
    "    X_test_euc_lap = laplacian_embedding(14, graph_list_euc_test, graph_category='euclidian_distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6753b2e3",
   "metadata": {},
   "source": [
    "# Node2Vec Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46817160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from node2vec import Node2Vec\n",
    "import networkx as nx\n",
    "\n",
    "class Node2Vec(Node2Vec):\n",
    "  \"\"\"\n",
    "  Parameters\n",
    "  ----------\n",
    "  p : float\n",
    "      p parameter of node2vec\n",
    "  q : float\n",
    "      q parameter of node2vec\n",
    "  d : int\n",
    "      dimensionality of the embedding vectors\n",
    "  \"\"\"\n",
    "  def __init__(self, graph, p=1, q=1, d=32):\n",
    "    super().__init__(\n",
    "                     graph = graph,\n",
    "                     walk_length=10,\n",
    "                     p=p,\n",
    "                     q=q,\n",
    "                     dimensions =d\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7511cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set dimension as 14 (75% representation power)\n",
    "def node2vec_embedding(graph_list):\n",
    "    # For Z-normalization\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    graph_node2vec_embeddings_list = []\n",
    "    i = 0\n",
    "\n",
    "    # Iterate through list of graphs\n",
    "    for graph in graph_list:\n",
    "        print(\"Example\", i)\n",
    "        # Apply Node2Vec to get embedding for each graph\n",
    "        n2v_model = Node2Vec(graph, 1, 1, 10)\n",
    "        model = n2v_model.fit(window=10, min_count=1, batch_words=4)\n",
    "        # Node2Vec representation\n",
    "        graph_node_embeddings = model.wv.vectors\n",
    "            \n",
    "        # Append the embeddings to the batch and their corresponding label\n",
    "        graph_node2vec_embeddings_list.append(graph_node_embeddings)   \n",
    "        i = i + 1\n",
    "\n",
    "    # Proceed with flattening and creating feature matrix (X_train) \n",
    "    flat_embeddings = [emb.flatten() for emb in graph_node2vec_embeddings_list]\n",
    "    X_train = np.array(flat_embeddings)\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f85603d-32c6-4f58-b3af-c930b9ee5e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cor_N2V = node2vec_embedding(graph_list_cor_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8959288-3577-4c67-8ea6-628bf1442c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cor_N2V = node2vec_embedding(graph_list_cor_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504df658-45c4-43b2-9d37-1960dce32bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_euc_N2V = node2vec_embedding(graph_list_euc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c187b917-049e-40cf-8402-f57447a72801",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_euc_N2V = node2vec_embedding(graph_list_euc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92901b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classifiers = ['SVC', 'KNC', 'DT', 'LR', 'MLP']\n",
    "def train_test_classifier_method12(graph_category, embedding_category, X_train, label_vector_train, X_test, \n",
    "                                   label_vector_test, classifier_name):\n",
    "    # Create and train the classifier\n",
    "    if classifier_name == 'SVC':\n",
    "        classifier = SVC(class_weight='balanced')\n",
    "    elif classifier_name == 'KNC':\n",
    "        classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "    elif classifier_name == 'DT':\n",
    "        classifier = DecisionTreeClassifier(random_state=42)\n",
    "    elif classifier_name == 'LR':\n",
    "        classifier = LogisticRegression(max_iter=10000)\n",
    "    elif classifier_name == 'MLP':\n",
    "        classifier = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000) \n",
    "    else:\n",
    "        classifier = SVC(class_weight='balanced')\n",
    "    # train selected classifier        \n",
    "    classifier.fit(X_train, label_vector_train)\n",
    "    # test selected classifier on unseen data\n",
    "    predictions = classifier.predict(X_test)\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    conf_matrix = confusion_matrix(label_vector_test, predictions)\n",
    "\n",
    "    # Calculate True Positives, True Negatives, False Positives, and False Negatives\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "    # Calculate True Skill Statistics (TSS)\n",
    "    tss = (tp / (tp + fn)) - (fp / (fp + tn))\n",
    "\n",
    "    # Calculate Heidke Skill Score 1 (HSS1)\n",
    "    hss1 = (tp / (tp + fn) )*(2 - (tp + fp)/tp )\n",
    "\n",
    "    # Calculate Heidke Skill Score 2 (HSS2)\n",
    "    hss2 = (2 * (tp * tn - fp * fn)) / ((tp + fn) * (tn + fn) + (tp + fp) * (tn + fp))\n",
    "\n",
    "    # Calculate F1 Score\n",
    "    f1 = f1_score(label_vector_test, predictions)\n",
    "\n",
    "    # Calculate Gilbert Skill Score\n",
    "    gilbert = (tp - (tp + fn) * (tp + fp) / (tp + tn + fp + fn)) / (tp + tn - (tp + fn) * (tp + fp) / (tp + tn + fp + fn))\n",
    "\n",
    "    # Calculate ROC AUC score\n",
    "    roc_auc = roc_auc_score(label_vector_test, predictions)\n",
    "    \n",
    "    # save the model\n",
    "    if graph_category == 'pearson_correlation':\n",
    "        graph_name = 'cor'\n",
    "    elif graph_category == 'euclidian_distance':\n",
    "        graph_name = 'euc'\n",
    "        \n",
    "    if embedding_category == 'laplacian':\n",
    "        em_name = 'lap'\n",
    "    elif embedding_category == 'Node2Vec':\n",
    "        em_name = 'n2v'\n",
    "        \n",
    "    cur_dir = Path.cwd()\n",
    "    model_name = training_partition + '_' + testing_partition + '_' + classifier_name + '_model_' + graph_name + em_name + '.pkl'\n",
    "    model_path = cur_dir.parent / 'MODELS' / model_name\n",
    "    \n",
    "    with open(model_path, 'wb') as model_file:\n",
    "        pickle.dump(classifier, model_file)\n",
    "\n",
    "    print(\"Saved \", classifier_name,\" to\", model_path)\n",
    "    # Print the results\n",
    "    print(classifier_name, \" Model Evaluation Metrics:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"True Skill Statistics (TSS):\", tss)\n",
    "    print(\"Heidke Skill Score 1 (HSS1):\", hss1)\n",
    "    print(\"Heidke Skill Score 2 (HSS2):\", hss2)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Gilbert Skill Score:\", gilbert)\n",
    "    print(\"ROC AUC Score:\", roc_auc)\n",
    "    print(\"********************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3497bab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all classifiers (COR-LAP)\n",
    "for classifier_name in classifiers:\n",
    "    train_test_classifier_method12('pearson_correlation', 'laplacian', \n",
    "                                   X_train_cor_lap, label_vector_cor_train, X_test_cor_lap, \n",
    "                                   label_vector_cor_test, classifier_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c280432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all classifiers (EUC-LAP)\n",
    "for classifier_name in classifiers:\n",
    "    train_test_classifier_method12('euclidian_distance', 'laplacian', \n",
    "                                   X_train_euc_lap, label_vector_euc_train, X_test_euc_lap, \n",
    "                                   label_vector_euc_test, classifier_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b177f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all classifiers (COR-N2V)\n",
    "for classifier_name in classifiers:\n",
    "    train_test_classifier_method12('pearson_correlation', 'Node2Vec', \n",
    "                                   X_train_cor_N2V, label_vector_cor_train, X_test_cor_N2V, \n",
    "                                   label_vector_cor_test, classifier_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d60a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all classifiers (EUC-N2V)\n",
    "for classifier_name in classifiers:\n",
    "    train_test_classifier_method12('euclidian_distance', 'Node2Vec', \n",
    "                                   X_train_euc_N2V, label_vector_euc_train, X_test_euc_N2V, \n",
    "                                   label_vector_euc_test, classifier_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d2794c",
   "metadata": {},
   "source": [
    "# Method 1.3: GCN\n",
    "\n",
    "- You can run GCN experiment for correlation graph data and euclidian graph data from gcn_cor_v1 & gcn_euc_v1 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dbb69b-defb-4d40-924e-1cd0246e85b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0567d56-eca5-4d73-aba2-ed26b80517f5",
   "metadata": {},
   "source": [
    "# Step 1: Get TS features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050c5c39-f679-42a6-9d9d-f9dd4bd714ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_g(folder_path, graph_category, is_nonflare_train=False):\n",
    "    data_list = []\n",
    "    \n",
    "    if is_nonflare_train:\n",
    "        csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv') and file.startswith('FQ')]\n",
    "    else:\n",
    "        csv_files = natsorted([file for file in os.listdir(folder_path) if file.endswith('.csv')])\n",
    "        \n",
    "    # determine number of extracted features \n",
    "    if graph_category == 'pearson_correlation':\n",
    "        n = 23\n",
    "    elif graph_category == 'euclidian_distance':\n",
    "        n = 24\n",
    "    # Loop through the sorted CSV files and load them into dataframes\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        # Use the file name (without extension) as the key in the dictionary\n",
    "        df = pd.read_csv(file_path, sep='\\t')\n",
    "        # Extract magnetic field parameter values\n",
    "        first_n_features = df.iloc[:, 1:n+1]\n",
    "        data_list.append(first_n_features)\n",
    "    \n",
    "    # Detect nan entries\n",
    "    nan_count = 0\n",
    "    indexes_with_nan = []\n",
    "    for index, df in enumerate(data_list):\n",
    "        if df.isna().any().any():\n",
    "            if index not in indexes_with_nan:\n",
    "                nan_count += 1\n",
    "                indexes_with_nan.append(index)\n",
    "    percentageNaN = (nan_count / len(data_list)) * 100\n",
    "    \n",
    "    # Discard nan entries\n",
    "    data_list = [df for index, df in enumerate(data_list) if index not in indexes_with_nan]\n",
    "    \n",
    "    return data_list, percentageNaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3115f773-f959-4192-ae50-e7a6cdb384bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For cor, extract TS data\n",
    "flare_data_list_train_cor, percentageNaN = process_data_g(folder_path_flare_train, \n",
    "                                                          'pearson_correlation')\n",
    "print(\"Number of DataFrames with NaN values among train flare examples: \", percentageNaN)\n",
    "nonflare_data_list_train_cor, percentageNaN  = process_data_g(folder_path_nonflare_train, \n",
    "                                                              'pearson_correlation',True)\n",
    "print(\"Number of DataFrames with NaN values among train nonflare examples: \", percentageNaN)\n",
    "flare_data_list_test_cor, percentageNaN  = process_data_g(folder_path_flare_test, 'pearson_correlation')\n",
    "print(\"Number of DataFrames with NaN values among test flare examples: \", percentageNaN)\n",
    "nonflare_data_list_test_cor, percentageNaN  = process_data_g(folder_path_nonflare_test, 'pearson_correlation')\n",
    "print(\"Number of DataFrames with NaN values among test nonflare examples: \", percentageNaN)\n",
    "\n",
    "\n",
    "# Combine TS flare and nonflare cor\n",
    "combined_ts_list_train_cor = np.concatenate([flare_data_list_train_cor, nonflare_data_list_train_cor], axis=0)\n",
    "combined_ts_list_test_cor = np.concatenate([flare_data_list_test_cor, nonflare_data_list_test_cor], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb333d0-9bf3-46ba-a95e-5421f815cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For euc, extract TS data\n",
    "flare_data_list_train_euc, percentageNaN = process_data_g(folder_path_flare_train, \n",
    "                                                          'euclidian_distance')\n",
    "print(\"Number of DataFrames with NaN values among train flare examples: \", percentageNaN)\n",
    "nonflare_data_list_train_euc, percentageNaN  = process_data_g(folder_path_nonflare_train, \n",
    "                                                              'euclidian_distance',True)\n",
    "print(\"Number of DataFrames with NaN values among train nonflare examples: \", percentageNaN)\n",
    "flare_data_list_test_euc, percentageNaN  = process_data_g(folder_path_flare_test, \n",
    "                                                          'euclidian_distance')\n",
    "print(\"Number of DataFrames with NaN values among test flare examples: \", percentageNaN)\n",
    "nonflare_data_list_test_euc, percentageNaN  = process_data_g(folder_path_nonflare_test, \n",
    "                                                             'euclidian_distance')\n",
    "print(\"Number of DataFrames with NaN values among test nonflare examples: \", percentageNaN)\n",
    "\n",
    "# Combine TS flare and nonflare cor\n",
    "combined_ts_list_train_euc = np.concatenate([flare_data_list_train_euc, nonflare_data_list_train_euc], axis=0)\n",
    "combined_ts_list_test_euc = np.concatenate([flare_data_list_test_euc, nonflare_data_list_test_euc], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f02f2c-a251-4082-a02a-ead5ec4fa4ef",
   "metadata": {},
   "source": [
    "# Step 2: Get graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754dad0e-8b45-4bf8-8146-76266ba7a276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "# this module will bring only the list of graphs \n",
    "def process_graphs_m13(partition_name, graph_category, train_or_test):\n",
    "    f_name = partition_name + '_' + train_or_test\n",
    "    cur_dir = Path.cwd()\n",
    "    graph_folder_input = cur_dir.parent / 'DATA' / 'graphs' # For specified graph path\n",
    "    graph_folder_input = graph_folder_input / graph_category / f_name\n",
    "    graph_list = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate through all files in the folder\n",
    "    for filename in os.listdir(graph_folder_input):\n",
    "        graph_path = os.path.join(graph_folder_input, filename)\n",
    "        try:\n",
    "            with open(graph_path, 'rb') as f:\n",
    "                G = pickle.load(f)\n",
    "            \n",
    "            if graph_category == 'pearson_correlation': \n",
    "                # IMPORTANT: DROP R-VALUE NODE(24'TH) TO MATCH FT SIZE\n",
    "                last_node = max(G.nodes())\n",
    "                G.remove_node(last_node)    \n",
    "           \n",
    "            # Determine label based on filename\n",
    "            if filename.startswith('flare'):\n",
    "                label = 1\n",
    "            elif filename.startswith('nonflare'):\n",
    "                label = 0\n",
    "        \n",
    "            # Append degrees and label to lists\n",
    "            graph_list.append(G)\n",
    "            labels.append(label)\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filename}: {str(e)}\")\n",
    "\n",
    "    # Convert lists to NumPy arrays\n",
    "    label_vector = np.array(labels)\n",
    "    print(\"Label Vector Shape:\", label_vector.shape)\n",
    "    return graph_list, label_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea926fa-c8ff-4cef-a994-b910aad7db93",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_list_cor_train, label_vector_cor_train=process_graphs_m13(partition_name=training_partition, \n",
    "                                                                  graph_category='pearson_correlation', train_or_test='train')\n",
    "graph_list_cor_test, label_vector_cor_test=process_graphs_m13(partition_name=testing_partition, \n",
    "                                                                graph_category='pearson_correlation', train_or_test='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896c12da-c07c-48cc-baf3-48f47ea26cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_list_euc_train, label_vector_euc_train = process_graphs_m13(partition_name=training_partition, \n",
    "                                                                    graph_category='euclidian_distance', train_or_test='train')\n",
    "graph_list_euc_test, label_vector_euc_test = process_graphs_m13(partition_name=testing_partition, \n",
    "                                                                  graph_category='euclidian_distance', train_or_test='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a96b62b-8ad7-43f2-8960-741886519f26",
   "metadata": {},
   "source": [
    "# Step 3: Custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc98df60-4f17-417e-ab40-506c8c695f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, graph_list, ts_list, labels):\n",
    "        self.graph_list = graph_list\n",
    "        self.ts_list = ts_list\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graph_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        graph = self.graph_list[idx]\n",
    "        ts = self.ts_list[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # For edges, we need to account for both directions of an edge\n",
    "        node_mapping = {node: i for i, node in enumerate(graph.nodes())}\n",
    "        edges = list(graph.edges())\n",
    "        all_edges = [(node_mapping[edge[0]], node_mapping[edge[1]]) for edge in edges]\n",
    "        all_edges += [(edge[1], edge[0]) for edge in all_edges]\n",
    "        edge_index = torch.tensor(all_edges, dtype=torch.long).t().contiguous()\n",
    "        \n",
    "        data = Data(x=torch.tensor(ts, dtype=torch.float).t(),\n",
    "                    edge_index=edge_index,\n",
    "                    y=torch.tensor(label, dtype=torch.float))\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed547310-7d98-46ad-b982-7b23b9e8f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders (for cor)\n",
    "train_dataset_cor = CustomDataset(graph_list_cor_train, combined_ts_list_train_cor, label_vector_cor_train)\n",
    "test_dataset_cor = CustomDataset(graph_list_cor_test, combined_ts_list_test_cor, label_vector_cor_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9718b8a-97de-40a0-afb2-d69d32f45184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders (for euc)\n",
    "train_dataset_euc = CustomDataset(graph_list_euc_train, combined_ts_list_train_euc, label_vector_euc_train)\n",
    "test_dataset_euc = CustomDataset(graph_list_euc_test, combined_ts_list_test_euc, label_vector_euc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b14e135-1bf4-4be8-a865-4923dcdec759",
   "metadata": {},
   "source": [
    "# Step 4: Training and testing of GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c10c48-1593-4d19-8548-8377deb8835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 2 layer gcn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "# Define the GCN model with a fully connected layer\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "        self.fc = nn.Linear(out_channels, 1)  # FC for 0-1 classification\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        #print(\"x.shape \", x.shape)\n",
    "        #print(\"edge_index.shape \", edge_index.shape)\n",
    "      \n",
    "        #print(\"X before conv 1\", x.shape)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        #print(\"X after conv 2, before pooling\", x.shape)\n",
    "        \n",
    "        x = x.view(data.num_graphs, int(x.shape[0]/data.num_graphs), x.shape[1])\n",
    "        x = torch.mean(x, dim=1)\n",
    "        #x = global_mean_pool(x, batch)\n",
    "        \n",
    "        #print(\"X after pooling, before fc \", x.shape)\n",
    "        x = self.fc(x)\n",
    "        #print(\"X after fc \", x.shape)\n",
    "        return torch.sigmoid(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663dad62-2773-42dd-9eb0-b983bada4977",
   "metadata": {},
   "source": [
    "# For correlation graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bca8714-9b05-4e0e-90b0-d648a421faa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "def custom_collate(batch):\n",
    "    # Use the Batch class from torch_geometric to handle variable-size graphs\n",
    "    return Batch.from_data_list(batch)\n",
    "\n",
    "# Create DataLoader instances withcustom collate function\n",
    "train_loader = DataLoader(train_dataset_cor, batch_size=64, shuffle=True, collate_fn=custom_collate)\n",
    "test_loader = DataLoader(test_dataset_cor, batch_size=64, shuffle=False, collate_fn=custom_collate)\n",
    "\n",
    "# Initialize GCN model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(in_channels=60, hidden_channels=64, out_channels=32).to(device)\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
    "        data = batch.to(device) \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, data.y.view(-1, 1).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update metrics\n",
    "        total_loss += loss.item()\n",
    "        total_samples += data.num_graphs\n",
    "        predicted_labels = (output >= 0.5).float()  # Threshold of 0.5 for binary classification\n",
    "        #print(predicted_labels, \"----\", data.y.view(-1, 1))\n",
    "        correct_predictions += (predicted_labels == data.y.view(-1, 1)).sum().item()\n",
    "        #print(\"CORRECT PRED \",correct_predictions, \"OUT OF\", total_samples)\n",
    "        \n",
    "    average_loss_epoch = total_loss / total_samples\n",
    "    accuracy_epoch = correct_predictions / total_samples\n",
    "    \n",
    "    train_losses.append(average_loss_epoch)\n",
    "    train_accuracies.append(accuracy_epoch)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss_epoch:.4f}, Accuracy: {accuracy_epoch:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d455af-3b4b-450b-ac60-6875372dd6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Epoch vs Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Epoch vs Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486eb671-5396-44eb-a364-ed99ad7a6865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Evaluate on the test set\n",
    "model.eval()\n",
    "true_labels, predicted_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader, desc='Testing'):\n",
    "        data = data.to(device)\n",
    "        output = (model(data) >= 0.5).float()\n",
    "        true_labels.extend(data.y.cpu().numpy())\n",
    "        predicted_labels.extend(output.cpu().numpy())\n",
    "\n",
    "# Convert to numpy arrays\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Extract values from confusion matrix\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate True Skill Statistics (TSS)\n",
    "tss = (tp / (tp + fn)) - (fp / (fp + tn))\n",
    "\n",
    "# Calculate Heidke Skill Score 1 (HSS1)\n",
    "hss1 = (tp / (tp + fn)) * (2 - (tp + fp) / tp)\n",
    "\n",
    "# Calculate Heidke Skill Score 2 (HSS2)\n",
    "hss2 = (2 * (tp * tn - fp * fn)) / ((tp + fn) * (tn + fn) + (tp + fp) * (tn + fp))\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate Gilbert Skill Score\n",
    "gilbert = (tp - (tp + fn) * (tp + fp) / (tp + tn + fp + fn)) / (\n",
    "        tp + tn - (tp + fn) * (tp + fp) / (tp + tn + fp + fn)\n",
    ")\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "roc_auc = roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "# Print the results\n",
    "print(\"GCN Model Evaluation Metrics:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"True Skill Statistics (TSS):\", tss)\n",
    "print(\"Heidke Skill Score 1 (HSS1):\", hss1)\n",
    "print(\"Heidke Skill Score 2 (HSS2):\", hss2)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Gilbert Skill Score:\", gilbert)\n",
    "print(\"ROC AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d778e1-3ced-4c15-ac55-388bc2245fc6",
   "metadata": {},
   "source": [
    "# For Euclidian graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cd9ce3-9e0c-49d0-a00f-9e1ad15f7ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "def custom_collate(batch):\n",
    "    # Use the Batch class from torch_geometric to handle variable-size graphs\n",
    "    return Batch.from_data_list(batch)\n",
    "\n",
    "# Create DataLoader instances withcustom collate function\n",
    "train_loader = DataLoader(train_dataset_euc, batch_size=64, shuffle=True, collate_fn=custom_collate)\n",
    "test_loader = DataLoader(test_dataset_euc, batch_size=64, shuffle=False, collate_fn=custom_collate)\n",
    "\n",
    "# Initialize GCN model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(in_channels=60, hidden_channels=64, out_channels=32).to(device)\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
    "        data = batch.to(device) \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, data.y.view(-1, 1).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update metrics\n",
    "        total_loss += loss.item()\n",
    "        total_samples += data.num_graphs\n",
    "        predicted_labels = (output >= 0.5).float()  # Threshold of 0.5 for binary classification\n",
    "        #print(predicted_labels, \"----\", data.y.view(-1, 1))\n",
    "        correct_predictions += (predicted_labels == data.y.view(-1, 1)).sum().item()\n",
    "        #print(\"CORRECT PRED \",correct_predictions, \"OUT OF\", total_samples)\n",
    "        \n",
    "    average_loss_epoch = total_loss / total_samples\n",
    "    accuracy_epoch = correct_predictions / total_samples\n",
    "    \n",
    "    train_losses.append(average_loss_epoch)\n",
    "    train_accuracies.append(accuracy_epoch)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss_epoch:.4f}, Accuracy: {accuracy_epoch:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0cb39a-b940-4f9f-934f-7be4e82ac2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Epoch vs Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Epoch vs Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef6f9d4-fd2e-49ad-a04d-2875aa791f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Evaluate on the test set\n",
    "model.eval()\n",
    "true_labels, predicted_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader, desc='Testing'):\n",
    "        data = data.to(device)\n",
    "        output = (model(data) >= 0.5).float()\n",
    "        true_labels.extend(data.y.cpu().numpy())\n",
    "        predicted_labels.extend(output.cpu().numpy())\n",
    "\n",
    "# Convert to numpy arrays\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Extract values from confusion matrix\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate True Skill Statistics (TSS)\n",
    "tss = (tp / (tp + fn)) - (fp / (fp + tn))\n",
    "\n",
    "# Calculate Heidke Skill Score 1 (HSS1)\n",
    "hss1 = (tp / (tp + fn)) * (2 - (tp + fp) / tp)\n",
    "\n",
    "# Calculate Heidke Skill Score 2 (HSS2)\n",
    "hss2 = (2 * (tp * tn - fp * fn)) / ((tp + fn) * (tn + fn) + (tp + fp) * (tn + fp))\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate Gilbert Skill Score\n",
    "gilbert = (tp - (tp + fn) * (tp + fp) / (tp + tn + fp + fn)) / (\n",
    "        tp + tn - (tp + fn) * (tp + fp) / (tp + tn + fp + fn)\n",
    ")\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "roc_auc = roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "# Print the results\n",
    "print(\"GCN Model Evaluation Metrics:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"True Skill Statistics (TSS):\", tss)\n",
    "print(\"Heidke Skill Score 1 (HSS1):\", hss1)\n",
    "print(\"Heidke Skill Score 2 (HSS2):\", hss2)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Gilbert Skill Score:\", gilbert)\n",
    "print(\"ROC AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b095858",
   "metadata": {},
   "source": [
    "#--------------------------------------------------------------#\n",
    "# by Onur Vural\n",
    "# Version Date: January 15, 2024\n",
    "#--------------------------------------------------------------#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
